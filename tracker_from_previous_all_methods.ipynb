{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Performs landmark localisation with initialisation (bbox) from the previous frame. \n",
    "\n",
    "Fundamental (preceding) tracker, where the first frame is provided and then export bb from each \n",
    "frame to be used for the next one. Adapted from run_online_tracking_all_methods.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from os.path import isdir, join, isfile, sep\n",
    "from os import listdir \n",
    "from functools import partial\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "from research_pyutils.path_related_functions import mkdir_p, rm_if_exists\n",
    "import logging\n",
    "from glob import glob\n",
    "\n",
    "# menpo packages imports\n",
    "import menpo.io as mio\n",
    "from menpodetect.dlib.conversion import pointgraph_to_rect\n",
    "from dlib import shape_predictor\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.visualize import print_progress\n",
    "from menpo.landmark import LandmarkGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the name of the computer, useful if running on condor\n",
    "import socket\n",
    "import time \n",
    "print(socket.gethostname())\n",
    "print(time.strftime(\"%d/%m/%Y, %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths and landmarks localisation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_base = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/300vw_testset/'\n",
    "assert(isdir(path_base))\n",
    "\n",
    "path_pickles = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/pickles/'\n",
    "assert(isdir(path_pickles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run for preceding tracker but for all landmark loc methods\n",
    "landm_loc_pool = ['dlibERT']  # aam\n",
    "fold_out_pool = ['tracking_preceding_' + i for i in landm_loc_pool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to process frame, clip and list of clips respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detection_to_pointgraph(detection):\n",
    "    return PointCloud(np.array([(p.y, p.x) for p in detection.parts()]))\n",
    "\n",
    "\n",
    "def process_frame(p_fr, lms, model):\n",
    "    \"\"\"\n",
    "    Processes one frame. Given a path to load the image, an lms (from the \n",
    "    previous frame) and a model, it fits the model and returns the fitting.\n",
    "    \"\"\"\n",
    "    im = mio.import_image(p_fr)\n",
    "    if im.n_channels == 3:\n",
    "        im = im.as_greyscale()\n",
    "        \n",
    "    if method_landm_loc == 'dlibERT':\n",
    "        im_pili = np.array(im.as_PILImage())\n",
    "        det_frame = model(im_pili, pointgraph_to_rect(lms))\n",
    "        init_pc = detection_to_pointgraph(det_frame)\n",
    "        ln_n = init_pc\n",
    "    else:\n",
    "        ft = model.fit_from_bb(im, lms)\n",
    "        ln_n = ft.fitted_image.landmarks['final'].copy()\n",
    "        del ft  # in menpofit <= 0.3.1, necessary to maintain reasonable ram (huge ft)\n",
    "    return ln_n, im.path.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preceding_tracker_clip(p_clip, p_ln, p_out, model, start=0):\n",
    "    \"\"\"\n",
    "    Processes a clip for the preceding tracker. \n",
    "    Initialises from the first frame the bb and then uses each frame's \n",
    "    landmarks to initialise the next frame.\n",
    "    \"\"\"\n",
    "    assert(isdir(p_clip) and isdir(p_out) and isdir(p_ln))\n",
    "    frames = sorted(listdir(p_clip))[start : ]  # exclude the first start frames\n",
    "    assert(len(frames) > 1)\n",
    "    # initialise the tracker (and the bb) with the first (start) frame\n",
    "    fr = frames[0]\n",
    "\n",
    "    # load the landmark and ensure it's a bb\n",
    "    bb_gl = glob(p_ln + fr[:fr.rfind('.')] + '*.pts')\n",
    "    assert(len(bb_gl) >= 1)\n",
    "    ln = mio.import_landmark_file(bb_gl[0])\n",
    "    bb = ln.lms.bounding_box()\n",
    "    \n",
    "    min_sz = np.array([10, 10])  # minimum size of bb we 'allow'. \n",
    "    for fr in print_progress(frames):  # iterate over all frames and run the tracker\n",
    "        bb1, name = process_frame(p_clip + fr, bb, model)\n",
    "        if isinstance(model, shape_predictor):\n",
    "            bb1 = LandmarkGroup.init_with_all_label(bb1)\n",
    "\n",
    "        bb = bb1.lms.bounding_box()  # initialisation bb for the next frame\n",
    "        mio.export_landmark_file(bb1, p_out + name + '.pts', overwrite=True)\n",
    "        \n",
    "        # if the bb is smaller than the min_sz, skip the rest of the frames\n",
    "        bp = bb.points\n",
    "        if np.any(np.max(bp, 0) - np.min(bp, 0) < min_sz):\n",
    "            print()\n",
    "            return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_tracker_clips(p_clips, p_in, p_out, model, start=0):\n",
    "    # calls the tracker for each clip, assuming pipeline format of folders.\n",
    "    assert(isdir(p_clips) and isdir(p_in))\n",
    "    clips = sorted(listdir(p_clips))[7:]\n",
    "    lcl = len(clips)\n",
    "    \n",
    "    for cnt, clip in enumerate(clips):\n",
    "        print('{} out of {} (Clip {})'.format(cnt + 1, lcl, clip))\n",
    "        preceding_tracker_clip(join(p_clips, clip, ''), join(p_in, clip, ''), \n",
    "                               mkdir_p(join(p_out, clip, '')), model, start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track all the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = listdir(path_base)\n",
    "model_bb = 'gt_bb'\n",
    "gt_fold = 'gt1_1_bb'  # used to load the first bb\n",
    "\n",
    "for f0 in range(len(fold_out_pool)):\n",
    "    fold_out = fold_out_pool[f0]\n",
    "    method_landm_loc = landm_loc_pool[f0]\n",
    "    print('method: {}, tracker: \\'preceding\\''.format(fold_out))\n",
    "    \n",
    "    # load prediction model\n",
    "    if method_landm_loc == 'dlibERT':\n",
    "        path_shape_pred = path_pickles + 'modelln_' +  model_bb + '_' + method_landm_loc + '.model'\n",
    "        assert(isfile(path_shape_pred))\n",
    "        model = shape_predictor(path_shape_pred)\n",
    "    else:\n",
    "        path_pkl = path_pickles + 'modelln_' +  model_bb + '_' + method_landm_loc + '.pkl'\n",
    "        assert(isfile(path_pkl))\n",
    "        model = mio.import_pickle(path_pkl)\n",
    "        \n",
    "    # for each category in the testset, run landmark loc method\n",
    "    for cat in cats:\n",
    "        if not cat[:8] == 'category' or not isdir(path_base + cat):\n",
    "            warn('Unknown content in path {} (folder: {}).'.format(path_base, cat))\n",
    "        print(cat)\n",
    "        # join or create the paths\n",
    "        p_fr = join(path_base, cat, 'frames', '')\n",
    "        p_ln_out_0 = mkdir_p(join(path_base, cat, fold_out, ''))\n",
    "        p_bb_in = mkdir_p(join(path_base, cat, gt_fold, ''))\n",
    "        assert(isdir(p_fr) and isdir(p_bb_in))\n",
    "        \n",
    "        call_tracker_clips(p_fr, p_bb_in, p_ln_out_0, model)\n",
    "\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "print(time.strftime(\"%d/%m/%Y, %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
