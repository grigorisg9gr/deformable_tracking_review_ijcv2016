{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes a function that loads images and their presaved bounding boxes and trains a landmark localisation method. \n",
    "\n",
    "Additionally, it includes code for verifying that the newly trained model performs 'reasonably' well on a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import isdir, join, sep\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "from random import shuffle\n",
    "\n",
    "import menpo.io as mio\n",
    "import dlib\n",
    "from menpofit.visualize import print_progress\n",
    "import random\n",
    "\n",
    "try:\n",
    "    %matplotlib inline\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are:\n",
    "\n",
    "    a) the base path of the training images, \n",
    "    \n",
    "    b) the name of the detection method (which is utilised to extract the bounding boxes), \n",
    "    \n",
    "    c) the name of the pickle folder (where the trained model will be exported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "detection_method = 'ramanan'\n",
    "detection_glob = detection_method + '_*'\n",
    "\n",
    "p0 = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/alignment_training/'\n",
    "det_p = join('/vol/atlas/homes/grigoris/misc/2016_ijcv/data/alignment_training_bb/', detection_method, '')\n",
    "assert(isdir(p0) and isdir(det_p))\n",
    "path_pickles = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/pickles/'\n",
    "assert(isdir(path_pickles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_images(img_p, det_p, ignore=False, detection_method=''):\n",
    "    \"\"\"\n",
    "    Loads the training images and the respective bounding box + grounthtruth points for each image.\n",
    "    The path with the landmark points is assumed to be the same as with the images and using the default menpo \n",
    "    behaviour, gt is loaded along with the image.\n",
    "    :param img_p:   (string) Path with the images.\n",
    "    :param det_p:   (string) Path with the bounding boxes. \n",
    "    :param ignore:  (bool, optional) Whether the images that have same bb as with gt should be loaded or not. \n",
    "                                     Only when detection_method != gt_bb.\n",
    "    :param detection_method: (string) Name of the detection method.\n",
    "    :return: (list) Loaded images for training.\n",
    "    \"\"\"\n",
    "    assert(isdir(img_p) and isdir(det_p))\n",
    "    assert(not (ignore and detection_method == 'gt_bb'))\n",
    "    train_images = []\n",
    "    ps = list(mio.image_paths(img_p))  # + '*_6.*'\n",
    "    for imn in print_progress(ps):\n",
    "        im = mio.import_image(imn)\n",
    "        try:\n",
    "            ln = mio.import_landmark_file(det_p + im.path.stem + '.pts')\n",
    "        except ValueError:\n",
    "            warn('The image {} is missing.'.format(im.path))\n",
    "            continue\n",
    "#             raise ValueError('The image {} is missing.'.format(im.path.stem))\n",
    "        if not (ln.lms.n_points == 4):\n",
    "            print(str(ln.path))\n",
    "            continue\n",
    "        im.landmarks['bb'] = ln\n",
    "        if ignore:  # find which ones have the same bb as the gt.\n",
    "            im.landmarks['gt'] = im.landmarks['PTS'].lms.bounding_box()\n",
    "            if np.all(ln.lms.points == im.landmarks['gt'].lms.points):\n",
    "                # ignore the images that have as \"detector's bb\" the gt bb\n",
    "                continue\n",
    "        im = im.crop_to_landmarks_proportion(0.3, 'bb')\n",
    "        train_images.append(im)\n",
    "    return train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# names of different databases with static images that exist on p0. \n",
    "# The images from these databases will be loaded by calling get_train_images().\n",
    "folds = ['ibug', 'afw', '300w', 'helen/trainset', 'helen/testset', 'lfpw/trainset', 'lfpw/testset']\n",
    "folds = ['ibug', '300w', 'lfpw/trainset']  # , 'helen/testset'\n",
    "images = []\n",
    "for fold in folds:\n",
    "    print(fold)\n",
    "    im1 = get_train_images(p0 + fold + sep, det_p + fold + sep, ignore=True)\n",
    "    assert(len(im1) > 50)\n",
    "    images += im1\n",
    "# shuffle(images)\n",
    "random.Random(9).shuffle(images)\n",
    "del im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reduce the ammount of images\n",
    "print('Images before reduction: {}'.format(len(images)))\n",
    "images = images[:min(len(images), 2500)]\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from menpowidgets import visualize_images\n",
    "# visualize_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Ensemble Regression Trees (One millisecond Face Alignment paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from menpofit.dlib import DlibERT\n",
    "\n",
    "model = DlibERT(images, group='PTS', bounding_box_group_glob='bb*',\n",
    "                scales=(1.0,), n_perturbations=0, n_dlib_perturbations=2, \n",
    "                n_iterations=14, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from menpowidgets import visualize_images\n",
    "# visualize_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_save_model = path_pickles + 'modelln_' + detection_method + '_dlibERT.model'\n",
    "# mio.export_pickle(model, p_save_model)\n",
    "\n",
    "m = model.algorithms[0].dlib_model\n",
    "m.save(p_save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.sdm import SupervisedDescentFitter\n",
    "from menpofit.sdm.algorithm import ParametricShapeNewton\n",
    "from functools import partial\n",
    "from menpofit.fitter import noisy_shape_from_bounding_box\n",
    "from menpo.feature import no_op, hellinger_vector_128_dsift, igo\n",
    "\n",
    "n_pert = 4\n",
    "n_iter = 4\n",
    "patch_features=[hellinger_vector_128_dsift, hellinger_vector_128_dsift, hellinger_vector_128_dsift, no_op]\n",
    "patch_shape=[(32, 32), (24, 24), (24, 24), (16, 16)]\n",
    "\n",
    "ridge_alpha = 200\n",
    "scale_perturb = 0.001\n",
    "rotation_perturb = 0\n",
    "translation_perturb = 0.05\n",
    "better_bb = partial(noisy_shape_from_bounding_box, noise_percentage=[scale_perturb, \n",
    "                                                                     rotation_perturb, \n",
    "                                                                     translation_perturb])\n",
    "\n",
    "print('Training Parametric Shape Ridge Regression SDM: Alpha {}'.format(ridge_alpha))\n",
    "\n",
    "sdm = SupervisedDescentFitter(\n",
    "    images,\n",
    "    group='PTS', \n",
    "    bounding_box_group_glob='bb',\n",
    "    reference_shape=None, \n",
    "    holistic_features=no_op, \n",
    "    sd_algorithm_cls=partial(ParametricShapeNewton, bias=True, alpha=ridge_alpha),\n",
    "                             #shape_model_cls=smaller_ortho_pdm(0.98)),\n",
    "#     patch_features=[partial(hellinger_vector_128_dsift, patch_shape=c) for c in [32, 24, 24, 16]],\n",
    "    patch_features=patch_features,\n",
    "    patch_shape=patch_shape,\n",
    "    diagonal=200,\n",
    "    scales=[0.5, 0.5, 1.0, 1.0],\n",
    "    n_iterations=n_iter,\n",
    "    n_perturbations=n_pert,\n",
    "    perturb_from_gt_bounding_box=better_bb, \n",
    "    batch_size=None,\n",
    "    verbose=True)\n",
    "\n",
    "p_save_model = path_pickles + 'modelln_' + detection_method + '_sdm.pkl'\n",
    "mio.export_pickle(sdm, p_save_model, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(0) # manual improvements in the sdm\n",
    "from menpofit.sdm import SupervisedDescentFitter\n",
    "from menpofit.sdm.algorithm import ParametricShapeNewton\n",
    "from functools import partial\n",
    "from menpofit.fitter import noisy_shape_from_bounding_box\n",
    "from menpo.feature import no_op, hellinger_vector_128_dsift, igo\n",
    "\n",
    "n_pert = 4\n",
    "n_iter = 4\n",
    "patch_features=[hellinger_vector_128_dsift, hellinger_vector_128_dsift, hellinger_vector_128_dsift, no_op]\n",
    "patch_shape=[(32, 32), (24, 24), (24, 24), (16, 16)]\n",
    "\n",
    "ridge_alpha = 200\n",
    "scale_perturb = 0.001\n",
    "rotation_perturb = 0\n",
    "translation_perturb = 0.05\n",
    "better_bb = partial(noisy_shape_from_bounding_box, noise_percentage=[scale_perturb, \n",
    "                                                                     rotation_perturb, \n",
    "                                                                     translation_perturb])\n",
    "\n",
    "print('Training Parametric Shape Ridge Regression SDM: Alpha {}'.format(ridge_alpha))\n",
    "\n",
    "sdm = SupervisedDescentFitter(\n",
    "    images,\n",
    "    group='PTS', \n",
    "    bounding_box_group_glob='bb',\n",
    "    reference_shape=None, \n",
    "    holistic_features=no_op, \n",
    "    sd_algorithm_cls=partial(ParametricShapeNewton, bias=True, alpha=ridge_alpha),\n",
    "                             #shape_model_cls=smaller_ortho_pdm(0.98)),\n",
    "#     patch_features=[partial(hellinger_vector_128_dsift, patch_shape=c) for c in [32, 24, 24, 16]],\n",
    "    patch_features=patch_features,\n",
    "    patch_shape=patch_shape,\n",
    "    diagonal=200,\n",
    "    scales=[0.5, 0.5, 1.0, 1.0],\n",
    "    n_iterations=n_iter,\n",
    "    n_perturbations=n_pert,\n",
    "    perturb_from_gt_bounding_box=better_bb, \n",
    "    batch_size=None,\n",
    "    verbose=True)\n",
    "\n",
    "p_save_model = path_pickles + 'sdm_valid/' + 'v1.2_modelln_' + detection_method \n",
    "#p_save_model += '_feats_' + patch_features[0].__name__ + '_patch_' \n",
    "p_save_model += '_patch_' \n",
    "p_save_model += str(patch_shape[0]) + '_' + str(patch_shape[1]) + '_perturb'\n",
    "p_save_model += str(n_pert) + '_iter' + str(n_iter) + '_images' + str(len(images)) + '_noop_sdm.pkl'\n",
    "mio.export_pickle(sdm, p_save_model, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpofit.sdm import RegularizedSDM\n",
    "from menpo.feature import fast_dsift, igo, no_op\n",
    "\n",
    "feature_pool = [[fast_dsift, no_op], [fast_dsift, fast_dsift], [no_op, no_op], [igo, no_op]]\n",
    "patch_shape_pool = [[(12, 12), (18, 18)]]\n",
    "pert_pool = [10, 15, 20]\n",
    "iter_pool = [6, 10, 12]\n",
    "scales = (.5, 1)\n",
    "crop = 0.2\n",
    "diagonal = 180\n",
    "\n",
    "def train_sdm(images, features, patch_shape, n_pert, n_iter, cnt):\n",
    "    fitter = RegularizedSDM(images, patch_features=features, verbose=True, \n",
    "                            diagonal=diagonal, n_perturbations=n_pert, group='PTS', \n",
    "                            patch_shape=patch_shape, alpha=100, n_iterations=n_iter, \n",
    "                            bounding_box_group_glob='bb*')\n",
    "    p_save_model = path_pickles + 'sdm_valid/' + 'modelln_' + detection_method + '_cnt' + str(cnt)\n",
    "    p_save_model += '_feats_' + features[0].__name__ + '_' + features[1].__name__ + '_patch_' \n",
    "    p_save_model += str(patch_shape[0]) + '_' + str(patch_shape[1]) + '_perturb'\n",
    "    p_save_model += str(n_pert) + '_iter' + str(n_iter) + '_images' + str(len(images)) + '_sdm.pkl'\n",
    "    mio.export_pickle(fitter, p_save_model, overwrite=True)\n",
    "\n",
    "    \n",
    "cnt = 0\n",
    "for features in feature_pool:\n",
    "    for patch_shape in patch_shape_pool:\n",
    "        for n_pert in pert_pool:\n",
    "            for n_iter in iter_pool:\n",
    "                cnt += 1\n",
    "                print('cnt: {}, patch shape: {}'.format(cnt, patch_shape))\n",
    "                train_sdm(images, features, patch_shape, n_pert, n_iter, cnt)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GN-DPM (patch aam) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final one chosen from validation below\n",
    "from menpo.feature import fast_dsift, igo, no_op\n",
    "from menpofit.aam import PatchAAM\n",
    "\n",
    "features = [fast_dsift, fast_dsift]\n",
    "patch_shape = [(10, 10), (24, 24)]\n",
    "scales = (.5, 1)\n",
    "crop = 0.2\n",
    "diagonal = 180\n",
    "\n",
    "\n",
    "aam = PatchAAM(images, verbose=True, holistic_features=features, patch_shape=patch_shape,\n",
    "               diagonal=diagonal, scales=scales, group='PTS')\n",
    "p_save_model = path_pickles + 'modelln_' + detection_method\n",
    "mio.export_pickle(aam, p_save_model + '_aam.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation with two levels pyramid\n",
    "from menpo.feature import fast_dsift, igo, no_op\n",
    "from menpofit.aam import PatchAAM\n",
    "\n",
    "p_save_model = path_pickles + 'aam_valid/modelln_' + detection_method\n",
    "feature_pool = [[fast_dsift, no_op], [fast_dsift, fast_dsift]]\n",
    "patch_shape_pool = [[(10, 10), (20, 20)], [(20, 20), (20, 20)], [(10, 10), (24, 24)], [(20, 20), (24, 24)]]\n",
    "scales = (.5, 1)\n",
    "crop = 0.2\n",
    "diagonal = 180\n",
    "\n",
    "cnt = 0\n",
    "for features in feature_pool:\n",
    "    for patch_shape in patch_shape_pool:\n",
    "        cnt = cnt + 1\n",
    "        print('cnt: {}, features: {}, patch shape: {}'.format(cnt, features, patch_shape))\n",
    "        aam = PatchAAM(images, verbose=True, holistic_features=features, patch_shape=patch_shape,\n",
    "                       diagonal=diagonal, scales=scales, group='PTS', batch_size=6000)\n",
    "        ns = p_save_model + '_aam_' + str(cnt) + '_feats_' + features[0].__name__\n",
    "        ns += features[1].__name__  + '_patch_' + str(patch_shape[0]) + '_'\n",
    "        ns += str(patch_shape[1]) + '_images' + str(len(images)) + '_aam.pkl'\n",
    "        aam.features = None\n",
    "        try:\n",
    "            mio.export_pickle(aam, ns, overwrite=True)\n",
    "        except:\n",
    "            import pickle\n",
    "            with open(ns, 'wb') as f:\n",
    "                pickle.dump(aam, f, protocol=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation with three levels pyramid\n",
    "from menpo.feature import fast_dsift, igo, no_op, hellinger_vector_128_dsift\n",
    "from menpofit.aam import PatchAAM\n",
    "\n",
    "p_save_model = path_pickles + 'aam_valid/modelln_' + detection_method\n",
    "feature_pool = [[fast_dsift, fast_dsift, no_op]]\n",
    "patch_shape_pool = [[(12, 12), (20, 20), (16, 16)], [(10, 10), (20, 20), (20, 20)], \n",
    "                   [(10, 10), (24, 24), (24, 24)]]\n",
    "scales = (.5, 1, 1)\n",
    "crop = 0.2\n",
    "diagonal = 180\n",
    "\n",
    "cnt = 0\n",
    "for features in feature_pool:\n",
    "    for patch_shape in patch_shape_pool:\n",
    "        cnt = cnt + 1\n",
    "        print('cnt: {}, features: {}, patch shape: {}'.format(cnt, features, patch_shape))\n",
    "        aam = PatchAAM(images, verbose=True, holistic_features=features, patch_shape=patch_shape,\n",
    "                       diagonal=diagonal, scales=scales, group='PTS')\n",
    "        ns = p_save_model + '_aam_' + str(cnt) + '_feats_' + features[0].__name__\n",
    "        ns += features[1].__name__ + features[2].__name__ + '_patch_' + str(patch_shape[0]) + '_'\n",
    "        ns += str(patch_shape[1]) + str(patch_shape[1]) + '_images' + str(len(images)) + '_aam.pkl'\n",
    "        aam.features = None\n",
    "        try:\n",
    "            mio.export_pickle(aam, ns, overwrite=True)\n",
    "        except:\n",
    "            import pickle\n",
    "            with open(ns, 'wb') as f:\n",
    "                pickle.dump(aam, f, protocol=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "from menpodetect.ffld2 import load_ffld2_frontal_face_detector\n",
    "\n",
    "\n",
    "def return_detector(detection):\n",
    "    if detection == 'dlib':\n",
    "        return load_dlib_frontal_face_detector()\n",
    "    elif detection == 'opencv':\n",
    "        from functools import partial\n",
    "        det = load_opencv_frontal_face_detector()\n",
    "        return partial(det, min_neighbours=3)\n",
    "    elif detection == 'ffld2':\n",
    "        return load_ffld2_frontal_face_detector()\n",
    "    else:\n",
    "        raise RuntimeError('Not a valid choice of detection ({}).'.format(detection))\n",
    "        \n",
    "detector = return_detector(detection_method)\n",
    "\n",
    "im = mio.import_builtin_asset.breakingbad_jpg()\n",
    "del im.landmarks['PTS']\n",
    "detector(im, group_prefix='bb')\n",
    "\n",
    "# im.view_landmarks()\n",
    "ll = model.fit_from_bb(im, im.landmarks['bb_0'].lms, max_iters=40)\n",
    "im2 = ll.fitted_image\n",
    "im2 = im2.crop_to_landmarks_proportion(0.3, group='final')\n",
    "im2.view_landmarks(group='final')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# im = mio.import_builtin_asset.breakingbad_jpg()\n",
    "# im = im.crop_to_landmarks_proportion(0.3)\n",
    "# random_rotations = np.random.randint(-20, 20, size=12)\n",
    "# rotated_images = [im.rotate_ccw_about_centre(r) for r in random_rotations]\n",
    "# for im_r in rotated_images:\n",
    "#     detector(im_r)\n",
    "#     try:\n",
    "#         ll = model.fit_from_bb(im, im.landmarks['dlib_0'].lms, max_iters=40)\n",
    "#     except KeyError:\n",
    "#         im_r.view_landmarks(group='PTS', new_figure=True)\n",
    "#         continue\n",
    "#     im2 = ll.fitted_image\n",
    "#     im2 = im2.crop_to_landmarks_proportion(0.3, group='final')\n",
    "#     im2.view_landmarks(group='final', new_figure=True)\n",
    "# #     im_r.view_landmarks(group='PTS', new_figure=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the new model with new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model trained above. Using a database i made, it checks that the fittings in unseen images make sense. There are asserts for mean error per image and the total error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import isdir, join, isfile\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import menpo.io as mio\n",
    "from dlib import shape_predictor\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.landmark import LandmarkGroup\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "from menpodetect.ffld2 import load_ffld2_frontal_face_detector\n",
    "from menpodetect.dlib.conversion import pointgraph_to_rect\n",
    "from menpofit.result import compute_normalise_point_to_point_error as comp_err\n",
    "from menpofit.visualize import print_progress\n",
    "\n",
    "def detection_to_pointgraph(detection):\n",
    "    return PointCloud(np.array([(p.y, p.x) for p in detection.parts()]))\n",
    "\n",
    "def compute_normalise_point_to_point_error_68(shape, gt_shape):\n",
    "    normalizer = np.linalg.norm(gt_shape.points[36, :] - gt_shape.points[45, :])\n",
    "    return comp_err(shape.points, gt_shape.points) / normalizer\n",
    "\n",
    "def return_detector(detection):\n",
    "    if detection == 'dlib':\n",
    "        return load_dlib_frontal_face_detector()\n",
    "    elif detection == 'opencv':\n",
    "        from functools import partial\n",
    "        det = load_opencv_frontal_face_detector()\n",
    "        return partial(det, min_neighbours=3)\n",
    "    elif detection == 'ffld2':\n",
    "        return load_ffld2_frontal_face_detector()\n",
    "    else:\n",
    "        raise RuntimeError('Not a valid choice of detection ({}).'.format(detection))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p0 = '/vol/atlas/homes/grigoris/Databases/personal/11_2015_test_localisation/'\n",
    "method_landm_loc = 'dlibERT'\n",
    "p_model = path_pickles + 'modelln_' + detection_method + '_dlibERT.model'\n",
    "p_model = path_pickles + 'modelln_' + 'gt_bb' + '_dlibERT.model'\n",
    "assert(isdir(p0) and isfile(p_model))\n",
    "# detector = load_dlib_frontal_face_detector()\n",
    "detector = return_detector(detection_method)\n",
    "\n",
    "if method_landm_loc == 'dlibERT':\n",
    "    predictor_dlib = shape_predictor(p_model)\n",
    "\n",
    "images = list(mio.import_images(p0))\n",
    "errors = []\n",
    "for im in print_progress(images):\n",
    "    im = im.crop_to_landmarks_proportion(0.3)\n",
    "    detector(im, group_prefix='bb')\n",
    "    l = list(im.landmarks.keys_matching('bb_*'))\n",
    "    if len(l) == 0:\n",
    "        print('No detection in {}.'.format(im.path.stem))\n",
    "        continue\n",
    "    assert(len(l) == 1)\n",
    "    ln = im.landmarks['bb_0']\n",
    "    if method_landm_loc == 'dlibERT':\n",
    "        im_pili = np.array(im.as_PILImage())\n",
    "        det_frame = predictor_dlib(im_pili, pointgraph_to_rect(ln.lms))\n",
    "        init_pc = detection_to_pointgraph(det_frame)\n",
    "    else:\n",
    "        ft = model.fit_from_bb(im, ln.lms)\n",
    "        init_pc = ft.final_shape\n",
    "    ln1 = LandmarkGroup.init_with_all_label(init_pc)\n",
    "    err = compute_normalise_point_to_point_error_68(ln1.lms, im.landmarks['PTS'].lms)\n",
    "    assert(err < 0.3)\n",
    "    errors.append(err)\n",
    "mean_err = np.mean(np.array(errors))\n",
    "assert(mean_err < 0.2)\n",
    "print('Successfully predicted with mean error {}.'.format(mean_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
