{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Called for detectors to export the bounding boxes in the testset. \n",
    "\n",
    "Additionally, it can at the same time apply a landmark localisation technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from os.path import isdir, join, isfile, sep\n",
    "from os import listdir \n",
    "from functools import partial\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "from research_pyutils.path_related_functions import mkdir_p, rm_if_exists\n",
    "import logging\n",
    "from pathlib import Path\n",
    "# workerbee is applied in order to call condor.\n",
    "from workerbee import exhaust_all_files_randomly\n",
    "\n",
    "# menpo packages imports\n",
    "import menpo.io as mio\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "from menpodetect.ffld2 import load_ffld2_frontal_face_detector\n",
    "from menpodetect.dlib.conversion import pointgraph_to_rect\n",
    "from dlib import shape_predictor\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.landmark import LandmarkGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths and detection + landmark localisation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_base = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/300vw_testset/'\n",
    "assert(isdir(path_base))\n",
    "\n",
    "path_pickles = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/pickles/'\n",
    "assert(isdir(path_pickles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_detection = 'opencv'\n",
    "# do not use with AAM, since it doesn't include the regression for the bounding boxes. \n",
    "method_landm_loc = 'sdm'\n",
    "\n",
    "fold_out = 'detection_' + method_detection + '_' + method_landm_loc\n",
    "save_bb = 1  # if set to 0, then it won't save the bb.\n",
    "fold_det_out = 'detector_' + method_detection  # save bb from the method\n",
    "detector = return_detector(method_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_detector(detection):\n",
    "    \"\"\"\n",
    "    Returns a partial function with the detector based on the (string) detection\n",
    "    that includes the name of the detector we wish to apply. \n",
    "    \"\"\"\n",
    "    if detection == 'dlib':\n",
    "        return load_dlib_frontal_face_detector()\n",
    "    elif detection == 'opencv':\n",
    "        from functools import partial\n",
    "        det = load_opencv_frontal_face_detector()\n",
    "        return partial(det, min_neighbours=3)\n",
    "    elif detection == 'ffld2':\n",
    "        return load_ffld2_frontal_face_detector()\n",
    "    else:\n",
    "        raise RuntimeError('Not a valid choice of detection ({}).'.format(detection))\n",
    "\n",
    "        \n",
    "def detection_to_pointgraph(detection):\n",
    "    return PointCloud(np.array([(p.y, p.x) for p in detection.parts()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load prediction model\n",
    "if method_landm_loc == 'dlibERT':\n",
    "    path_shape_pred = path_pickles + 'modelln_' +  method_detection + '_' + method_landm_loc + '.model'\n",
    "    assert(isfile(path_shape_pred))\n",
    "    model = shape_predictor(path_shape_pred)\n",
    "else:\n",
    "    path_pkl = path_pickles + 'modelln_' +  method_detection + '_' + method_landm_loc + '.pkl'\n",
    "    assert(isfile(path_pkl))\n",
    "    model = mio.import_pickle(path_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_path(p0, name):\n",
    "    assert(isdir(p0))\n",
    "    p1 = join(p0, name, '')\n",
    "    if not isdir(p1):\n",
    "        mkdir_p(p1)\n",
    "    return p1\n",
    "    \n",
    "def process_frame(p_fr):\n",
    "    # using global: detector(), p_ln_out_0, model, p_condor_dummy_0, p_bb_out_0, save_bb\n",
    "    try:\n",
    "        im = mio.import_image(p_fr)\n",
    "        if im.n_channels == 3:\n",
    "            im = im.as_greyscale()\n",
    "        detector(im)\n",
    "        assert(im.landmarks.n_groups < 10)  # might get complicated otherwise with the naming\n",
    "        if im.landmarks.n_groups > 0:  # there are detections\n",
    "            ln = im.landmarks[im.landmarks.group_labels[0]]\n",
    "            \n",
    "            if save_bb:\n",
    "                p_bb_out = _get_path(p_bb_out_0, im.path.parent.name) + im.path.stem + '.pts'\n",
    "                mio.export_landmark_file(ln, p_bb_out, overwrite=True)\n",
    "            \n",
    "            p_out = _get_path(p_ln_out_0, im.path.parent.name) + im.path.stem + '.pts'\n",
    "            \n",
    "            # ensure that the bb is inside the bounds\n",
    "            im.landmarks['bb'] = ln\n",
    "            im.constrain_landmarks_to_bounds()\n",
    "            ln = im.landmarks['bb']\n",
    "\n",
    "            if method_landm_loc == 'dlibERT':\n",
    "                im_pili = np.array(im.as_PILImage())\n",
    "                det_frame = model(im_pili, pointgraph_to_rect(ln.lms))\n",
    "                init_pc = detection_to_pointgraph(det_frame)\n",
    "                mio.export_landmark_file(LandmarkGroup.init_with_all_label(init_pc), \n",
    "                                         p_out, overwrite=True)\n",
    "            else:\n",
    "                ft = model.fit_from_bb(im, ln.lms)\n",
    "                im.landmarks['gg'] = ft.final_shape\n",
    "                mio.export_landmark_file(im.landmarks['gg'], p_out, overwrite=True)\n",
    "        else:  # temp, can be removed, debugging purposes. \n",
    "            print(\"The input '{}' has no ln.\".format(p_fr))\n",
    "        \n",
    "        # create dummy file for workerbee\n",
    "        p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "        open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "    except Exception as e:\n",
    "        print(\"The input '{}' failed.\".format(p_fr))\n",
    "        logging.exception(\"The input '{}' failed.\".format(p_fr))\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute for all categories, all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = listdir(path_base)\n",
    "for cat in cats:\n",
    "    if not cat[:8] == 'category' or not isdir(path_base + cat):\n",
    "        warn('Unknown content in path {} (folder: {}).'.format(path_base, cat))\n",
    "    print(cat)\n",
    "    # join or create the paths\n",
    "    p_cat = join(path_base, cat, '')\n",
    "    p_fr = join(p_cat, 'frames', '')\n",
    "    assert(isdir(p_fr))  # frames folder should exist\n",
    "    p_ln_out_0 = mkdir_p(join(p_cat, fold_out, ''))\n",
    "    p_bb_out_0 = mkdir_p(join(p_cat, fold_det_out, ''))\n",
    "    # the condor path below is utilised just to save some dummy files. That \n",
    "    # way workerbee will know that this frame has been processed and can measure the progress.\n",
    "    p_condor_dummy_0 = mkdir_p(join(p_cat, 'condor_tmp', 'condor_dummy_' + fold_out, ''))\n",
    "    \n",
    "    for c in sorted(listdir(p_fr)):   # for each clip\n",
    "        output_dir = Path(mkdir_p(p_condor_dummy_0 + c + sep))\n",
    "        done = lambda: output_dir.glob('*.pts')\n",
    "        im_paths = lambda: mio.image_paths(p_fr + c + sep + '*')\n",
    "        exhaust_all_files_randomly(im_paths, done, process_frame, verbose=True)\n",
    "    # uncomment below, only if NOT called in condor.\n",
    "    # rm_if_exists(p_condor_dummy_0)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
