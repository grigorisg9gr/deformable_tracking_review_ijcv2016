{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import isdir, join\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "from random import shuffle\n",
    "\n",
    "import menpo.io as mio\n",
    "import dlib\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "from menpodetect.ffld2 import load_ffld2_frontal_face_detector\n",
    "from menpofit.visualize import print_progress\n",
    "\n",
    "try:\n",
    "    %matplotlib inline\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_images(img_p, det_p):\n",
    "    assert(isdir(img_p) and isdir(det_p))\n",
    "    train_images = []\n",
    "    ps = list(mio.image_paths(img_p))\n",
    "    for imn in print_progress(ps):\n",
    "        im = mio.import_image(imn)\n",
    "        try:\n",
    "            ln = mio.import_landmark_file(det_p + im.path.stem + '.pts')\n",
    "        except ValueError:\n",
    "            warn('The image {} is missing.'.format(im.path))\n",
    "            continue\n",
    "#             raise ValueError('The image {} is missing.'.format(im.path.stem))\n",
    "        if not (ln.lms.n_points == 4):\n",
    "            print(str(ln.path))\n",
    "            continue\n",
    "        im.landmarks['bb'] = ln\n",
    "        train_images.append(im)\n",
    "    return train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "detection_method = 'ffld2'\n",
    "detection_glob = detection_method + '_*'\n",
    "\n",
    "p0 = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/alignment_training/'\n",
    "det_p = join('/vol/atlas/homes/grigoris/misc/2016_ijcv/data/alignment_training_bb/', detection_method, '')\n",
    "assert(isdir(p0) and isdir(det_p))\n",
    "path_pickles = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/pickles/'\n",
    "assert(isdir(path_pickles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folds = ['ibug', 'afw', '300w', 'helen/trainset', 'helen/testset', 'lfpw/trainset', 'lfpw/testset']\n",
    "images = []\n",
    "for fold in folds:\n",
    "    print(fold)\n",
    "    im1 = get_train_images(p0 + fold + '/', det_p + fold + '/')\n",
    "    assert(len(im1) > 50)\n",
    "    images += im1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Ensemble Regression Trees (One millisecond Face Alignment paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from menpofit.dlib import DlibERT\n",
    "\n",
    "model = DlibERT(images, group='PTS', bounding_box_group_glob='bb*',\n",
    "                scales=(1.0,), n_perturbations=0, n_dlib_perturbations=2, \n",
    "                n_iterations=14, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from menpowidgets import visualize_images\n",
    "# visualize_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_save_model = path_pickles + 'modelln_' + detection_method + '_dlibERT.model'\n",
    "# mio.export_pickle(model, p_save_model)\n",
    "\n",
    "m = model.algorithms[0].dlib_model\n",
    "m.save(p_save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GN-DPM (patch aam) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from menpo.feature import fast_dsift\n",
    "# from menpofit.aam import PatchAAM, LucasKanadeAAMFitter\n",
    "\n",
    "# features = fast_dsift\n",
    "# patch_shape = (18, 18)\n",
    "# crop = 0.2\n",
    "# diagonal = 180\n",
    "# # n_shape=[4, 15]\n",
    "# # n_appearance=[60, 150]\n",
    "\n",
    "# aam = PatchAAM(images, verbose=True, holistic_features=features, patch_shape=patch_shape,\n",
    "#                diagonal=diagonal, scales=(1.), group='PTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_detector(detection):\n",
    "    if detection == 'dlib':\n",
    "        return load_dlib_frontal_face_detector()\n",
    "    elif detection == 'opencv':\n",
    "        from functools import partial\n",
    "        det = load_opencv_frontal_face_detector()\n",
    "        return partial(det, min_neighbours=3)\n",
    "    elif detection == 'ffld2':\n",
    "        return load_ffld2_frontal_face_detector()\n",
    "    else:\n",
    "        raise RuntimeError('Not a valid choice of detection ({}).'.format(detection))\n",
    "        \n",
    "detector = return_detector(detection_method)\n",
    "\n",
    "im = mio.import_builtin_asset.breakingbad_jpg()\n",
    "del im.landmarks['PTS']\n",
    "detector(im, group_prefix='bb')\n",
    "\n",
    "# im.view_landmarks()\n",
    "ll = model.fit_from_bb(im, im.landmarks['bb_0'].lms, max_iters=40)\n",
    "im2 = ll.fitted_image\n",
    "im2 = im2.crop_to_landmarks_proportion(0.3, group='final')\n",
    "im2.view_landmarks(group='final')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# im = mio.import_builtin_asset.breakingbad_jpg()\n",
    "# im = im.crop_to_landmarks_proportion(0.3)\n",
    "# random_rotations = np.random.randint(-20, 20, size=12)\n",
    "# rotated_images = [im.rotate_ccw_about_centre(r) for r in random_rotations]\n",
    "# for im_r in rotated_images:\n",
    "#     detector(im_r)\n",
    "#     try:\n",
    "#         ll = model.fit_from_bb(im, im.landmarks['dlib_0'].lms, max_iters=40)\n",
    "#     except KeyError:\n",
    "#         im_r.view_landmarks(group='PTS', new_figure=True)\n",
    "#         continue\n",
    "#     im2 = ll.fitted_image\n",
    "#     im2 = im2.crop_to_landmarks_proportion(0.3, group='final')\n",
    "#     im2.view_landmarks(group='final', new_figure=True)\n",
    "# #     im_r.view_landmarks(group='PTS', new_figure=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the new model with new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model trained above. Using a database i made, it checks that the fittings in unseen images make sense. There are asserts for mean error per image and the total error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import isdir, join, isfile\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import menpo.io as mio\n",
    "from dlib import shape_predictor\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.landmark import LandmarkGroup\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "from menpodetect.ffld2 import load_ffld2_frontal_face_detector\n",
    "from menpodetect.dlib.conversion import pointgraph_to_rect\n",
    "from menpofit.result import compute_normalise_point_to_point_error as comp_err\n",
    "from menpofit.visualize import print_progress\n",
    "\n",
    "def detection_to_pointgraph(detection):\n",
    "    return PointCloud(np.array([(p.y, p.x) for p in detection.parts()]))\n",
    "\n",
    "def compute_normalise_point_to_point_error_68(shape, gt_shape):\n",
    "    normalizer = np.linalg.norm(gt_shape.points[36, :] - gt_shape.points[45, :])\n",
    "    return comp_err(shape.points, gt_shape.points) / normalizer\n",
    "\n",
    "def return_detector(detection):\n",
    "    if detection == 'dlib':\n",
    "        return load_dlib_frontal_face_detector()\n",
    "    elif detection == 'opencv':\n",
    "        from functools import partial\n",
    "        det = load_opencv_frontal_face_detector()\n",
    "        return partial(det, min_neighbours=3)\n",
    "    elif detection == 'ffld2':\n",
    "        return load_ffld2_frontal_face_detector()\n",
    "    else:\n",
    "        raise RuntimeError('Not a valid choice of detection ({}).'.format(detection))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p0 = '/vol/atlas/homes/grigoris/Databases/personal/11_2015_test_localisation/'\n",
    "method_landm_loc = 'dlibERT'\n",
    "p_model = path_pickles + 'modelln_' + detection_method + '_dlibERT.model'\n",
    "assert(isdir(p0) and isfile(p_model))\n",
    "# detector = load_dlib_frontal_face_detector()\n",
    "detector = return_detector(detection_method)\n",
    "\n",
    "if method_landm_loc == 'dlibERT':\n",
    "    predictor_dlib = shape_predictor(p_model)\n",
    "\n",
    "images = list(mio.import_images(p0))\n",
    "errors = []\n",
    "for im in print_progress(images):\n",
    "    im = im.crop_to_landmarks_proportion(0.3)\n",
    "    detector(im, group_prefix='bb')\n",
    "    l = list(im.landmarks.keys_matching('bb_*'))\n",
    "    if len(l) == 0:\n",
    "        print('No detection in {}.'.format(im.path.stem))\n",
    "        continue\n",
    "    assert(len(l) == 1)\n",
    "    ln = im.landmarks['bb_0']\n",
    "    if method_landm_loc == 'dlibERT':\n",
    "        im_pili = np.array(im.as_PILImage())\n",
    "        det_frame = predictor_dlib(im_pili, pointgraph_to_rect(ln.lms))\n",
    "        init_pc = detection_to_pointgraph(det_frame)\n",
    "    else:\n",
    "        ft = model.fit_from_bb(im, ln.lms)\n",
    "        init_pc = ft.final_shape\n",
    "    ln1 = LandmarkGroup.init_with_all_label(init_pc)\n",
    "    err = compute_normalise_point_to_point_error_68(ln1.lms, im.landmarks['PTS'].lms)\n",
    "    assert(err < 0.3)\n",
    "    errors.append(err)\n",
    "mean_err = np.mean(np.array(errors))\n",
    "assert(mean_err < 0.2)\n",
    "print('Successfully predicted with mean error {}.'.format(mean_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
