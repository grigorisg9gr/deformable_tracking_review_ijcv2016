{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Performs landmark localisation on the 300vw testset.\n",
    "\n",
    "It works in batch mode, i.e. run the landmark localisation for\n",
    "\n",
    "all the methods defined. \n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "It expects the following inputs:\n",
    "\n",
    "   a) The trained landmark localisation models,\n",
    "\n",
    "   b) The bounding boxes of the trackers/detectors exported,\n",
    "\n",
    "   c) The frames.\n",
    "\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "The structure is assumed the same as in all notebooks, i.e. as \n",
    "\n",
    "indicated below.\n",
    "\n",
    "\n",
    "\n",
    "It is highly recommended to use zero-padding in the frame names and\n",
    "\n",
    "the respective landmark files, because otherwise it depends on the OS\n",
    "\n",
    "to interpret the sequence of frames.\n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "Developed on menpo.0.6 version.\n",
    "\n",
    "Updated for the latest menpo.0.7.5 version, September 2016. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "(expected folder structure)\n",
    "\n",
    "path_base_testset\n",
    "└───category1\n",
    "    │\n",
    "    └─── frames\n",
    "            │\n",
    "            └─── [name_of_clip] (e.g. 541)\n",
    "                    │ [frame_name].[extension] (e.g. 000001.png)\n",
    "                    │ [frame_name].[extension] (e.g. 000002.png)\n",
    "                    │ ...\n",
    "            │ ...\n",
    "    │\n",
    "    └─── gt_landmarks  (not required for executing the code)\n",
    "            │\n",
    "            └─── [name_of_clip]\n",
    "                    │ [file_name].[extension] (e.g. 000001.pts)\n",
    "                    │ ...\n",
    "            │ ...\n",
    "    │\n",
    "    └─── [detector/tracker]_[method_name] (e.g. detector_opencv, tracker_cmt)\n",
    "            │\n",
    "            └─── [name_of_clip]\n",
    "                    │ [file_name].[extension] (e.g. 000001.pts)\n",
    "                    │ ...\n",
    "            │ ...\n",
    " └───category2\n",
    "    │ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from os.path import isdir, join, isfile, sep\n",
    "from os import listdir \n",
    "from functools import partial\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from workerbee import exhaust_all_files_randomly\n",
    "\n",
    "# menpo packages imports\n",
    "import menpo.io as mio\n",
    "from menpodetect.dlib.conversion import pointgraph_to_rect\n",
    "from dlib import shape_predictor\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.landmark import LandmarkGroup\n",
    "from menpo.transform import Scale, Translation\n",
    "\n",
    "try:\n",
    "    from research_pyutils import mkdir_p, rm_if_exists, execution_stats\n",
    "    from research_pyutils.menpo_related import compute_overlap\n",
    "except ImportError:\n",
    "    m1 = ('The import failed, please check that you have the\\n'\n",
    "          'package research_pyutils from here: \\n'\n",
    "          'https://github.com/grigorisg9gr/pyutils \\n')\n",
    "    raise ImportError(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# auxiliary, print stats, no functional purpose\n",
    "execution_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base path where the frames and landmarks exist/will be saved into.\n",
    "path_base = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/300vw_testset/'\n",
    "assert(isdir(path_base))\n",
    "\n",
    "# base path for the trained landmark localisation models.\n",
    "path_pickles = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/pickles/'\n",
    "assert(isdir(path_pickles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detection_to_pointgraph(detection):\n",
    "    return PointCloud(np.array([(p.y, p.x) for p in detection.parts()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _get_path(p0, name):\n",
    "    # Join the path and ensure it exists.\n",
    "    assert(isdir(p0))\n",
    "    p1 = join(p0, name, '')\n",
    "    if not isdir(p1):\n",
    "        mkdir_p(p1)\n",
    "    return p1\n",
    "\n",
    "\n",
    "def return_scale(pt, target_sz):\n",
    "    # find the current range of the bb (pt) and the scaling required \n",
    "    # to reach the target_sz. Used for the regression in \n",
    "    # detector's AAM only. \n",
    "    target_sz = np.array(target_sz) * 1.0\n",
    "    range0 = np.max(pt, axis=0) - np.min(pt, axis=0)\n",
    "    assert(np.min(range0) > 0)\n",
    "    scale = target_sz / range0\n",
    "    return scale\n",
    "\n",
    "\n",
    "def aam_regression(im, g):\n",
    "    # using global regr1, reg_f.\n",
    "    # The function resizes the bb based on the regression \n",
    "    # training, that is to  scale/translate the detectors' \n",
    "    # bb towards the gt bb.  It initially resizes the image, \n",
    "    # extracts the feats, acquires  the prediction and then \n",
    "    # applies it on the detectors' bb.\n",
    "    \n",
    "    # Resizes the images based on the target_sz, extracts the \n",
    "    # feats in the resized bb, fit the regression, gets the \n",
    "    # prediction and applies the transform to the image.\n",
    "    target_sz = reg_f['target_size']\n",
    "    feats = reg_f['feats']\n",
    "    \n",
    "    sc1 = return_scale(im.landmarks[g].lms.points, target_sz)\n",
    "    im2 = im.resize(sc1 * im.shape)\n",
    "\n",
    "    pt = im2.landmarks[g].lms.points\n",
    "    min_idx = np.round(np.min(pt, axis=0))\n",
    "    # often the size of the bb is 1 pixel off, so we specifically crop \n",
    "    #it to be in the target_sz.\n",
    "    im3 = feats(im2.crop(min_idx, min_idx + target_sz))\n",
    "    ft = np.reshape(im3.pixels, -1)\n",
    "    # predict from regression method\n",
    "    ft = ft.reshape(1, -1)  # avoid annoying warning of sklearn\n",
    "    pred = regr1.predict(ft)\n",
    "    \n",
    "    # get the reshaped bb, based on the prediction of the regressor.\n",
    "    # WARNING: The scaling as defined in the training is a pure scaling of the \n",
    "    # width, height, while with the transform in menpo, the bounding box moves\n",
    "    # towards [0,0], so we account for this change and add it to the translation.\n",
    "    scale = Scale(pred[0, 0 : 2])\n",
    "    centre = im.landmarks[g].lms.centre()\n",
    "    pcloud = scale.apply(im.landmarks[g].lms)\n",
    "    im.landmarks['pred'] = pcloud\n",
    "    diff_centre = centre - im.landmarks['pred'].lms.centre()\n",
    "    \n",
    "    transl = Translation(pred[0, 2 : 4] + diff_centre)\n",
    "    pcloud = transl.apply(im.landmarks['pred'].lms)\n",
    "    # the new bb is saved as pred landmark in the original image\n",
    "    im.landmarks['pred'] = pcloud\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "    \n",
    "def process_frame(p_fr):\n",
    "    \"\"\"\n",
    "    Main processing function per frame. \n",
    "    It loads the frame, applies landmark localisation\n",
    "    technique and exports the landmark file.\n",
    "    \n",
    "    The function predicts several corner cases that emerged\n",
    "    during fitting different methods, thus the code was \n",
    "    adapted to fit those, thus it is greater in extent than\n",
    "    a simple fitting. \n",
    "    \n",
    "    An additional complication factor is the workerbee for\n",
    "    running the fitting in a batch mode (cluster). \n",
    "    Specifically, several variables are globals, due to the\n",
    "    current workerbee version that accepts only p_fr as the\n",
    "    variable to pass to the calling function.\n",
    "    \n",
    "    Furthermore, this workerbee version decides on the next\n",
    "    task based on the written filenames, thus for every \n",
    "    frame processed, there is a dummy file written in a \n",
    "    different path, even if the landmark localisation \n",
    "    technique is not applied. \n",
    "    \n",
    "    Globals used: p_ln_out_0, model, p_condor_dummy_0, \n",
    "                  p_bb_out_0, min_sz, method_landm_loc,\n",
    "                  fold_out.\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "        # # # # # #   Load the image and search for detections.   # # # # # #\n",
    "        # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "        im = mio.import_image(p_fr, landmark_resolver=None)\n",
    "        if im.n_channels == 3:\n",
    "            im = im.as_greyscale()\n",
    "        p_bb_out = _get_path(p_bb_out_0, im.path.parent.name) + im.path.stem\n",
    "        if isfile(p_bb_out + '.pts'):  # allow the _0.pts extension\n",
    "            p_bb_out += '.pts'\n",
    "        else:\n",
    "            p_bb_out += '_0.pts'\n",
    "\n",
    "        if isfile(p_bb_out):\n",
    "            # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "            # # # # #  Load the detection and perform sanity checks.  # # # # # #\n",
    "            # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "            ln = mio.import_landmark_file(p_bb_out)\n",
    "            if ln.lms.n_points == 0:\n",
    "                print('The ln {} has 0 values in the ln.'.format(ln.path.stem))\n",
    "                # create dummy file for workerbee\n",
    "                p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "                open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "                return  \n",
    "            assert(ln.lms.n_points == 4)\n",
    "            \n",
    "            # catch the case of nan or overflowed values and don't try to fit those.\n",
    "            if ln.lms.has_nan_values() or np.any(ln.lms.points > 1e6):\n",
    "                print('The ln {} has nan or overflowed values.'.format(ln.path.stem))\n",
    "                # create dummy file for workerbee\n",
    "                p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "                open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "                return                \n",
    "\n",
    "            p_out = _get_path(p_ln_out_0, im.path.parent.name) + im.path.stem + '.pts'\n",
    "            # ensure that the bb is inside the bounds\n",
    "            try:\n",
    "                ln = ln.lms.constrain_to_bounds(im.bounds())\n",
    "            except:\n",
    "                # The code below is for menpo versions before 0.7.\n",
    "                # This will be removed in future version though.\n",
    "                im.landmarks['bb'] = ln\n",
    "                im.constrain_landmarks_to_bounds()\n",
    "                ln = im.landmarks['bb']\n",
    "            \n",
    "            # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "            # # # # # #  Perform landmark localisation for a method.  # # # # # #\n",
    "            # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "            if method_landm_loc == 'dlibERT':\n",
    "                im_pili = np.array(im.as_PILImage())\n",
    "                det_frame = model(im_pili, pointgraph_to_rect(ln.lms))\n",
    "                init_pc = detection_to_pointgraph(det_frame)\n",
    "                mio.export_landmark_file(LandmarkGroup.init_with_all_label(init_pc), \n",
    "                                         p_out, overwrite=True)\n",
    "            else:\n",
    "                # The following 'if' hack to load regression model for AAM.\n",
    "                if ('aam' in fold_out) and ('detection' in fold_out):\n",
    "                    pred = aam_regression(im, 'bb')\n",
    "                    ov1 = compute_overlap(im.landmarks['pred'].lms.points, \n",
    "                                          ln.lms.points)\n",
    "                    # detectors are not too off in their prediction, so require\n",
    "                    # some minimum overlap to replace with the regression's bb.\n",
    "                    if ov1 > 0.45 :\n",
    "                        ln = im.landmarks['pred']\n",
    "                        ln = ln.lms.constrain_to_bounds(im.bounds())\n",
    "                        \n",
    "                # request a minimum size of bb, otherwise menpofit might crash.\n",
    "                bp = ln.lms.points\n",
    "                if np.all(np.max(bp, 0) - np.min(bp, 0) >= min_sz): \n",
    "                    ft = model.fit_from_bb(im, ln.lms)\n",
    "                    im.landmarks['gg'] = ft.final_shape\n",
    "                    mio.export_landmark_file(im.landmarks['gg'], p_out, overwrite=True)\n",
    "                    print(' successfully fitted')  # helps in condor\n",
    "\n",
    "        \n",
    "        # create dummy file for workerbee\n",
    "        p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "        open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "    except Exception as e:\n",
    "        # We catch any type of exception here, in order to allow the \n",
    "        # algorithm to continue the execution with the rest landmarks.\n",
    "        # Can be off for debugging or experimentation. \n",
    "        print(e)\n",
    "        if 'p_out' in locals():\n",
    "            print(\"The input '{}' failed with p_ln '{}'.\".format(p_fr, p_out))\n",
    "        logging.exception(\"The input '{}' failed.\".format(p_fr))\n",
    "        if ('aam' in fold_out) and ('detection' in fold_out):\n",
    "            # hack to load regression model \n",
    "            try:\n",
    "                print(e)\n",
    "                # create dummy file for workerbee\n",
    "                p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "                open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# minimum size of bb we 'allow'. Less than that, there is no \n",
    "# fitting in SDM/AAM.\n",
    "min_sz = np.array([10, 10])\n",
    "# landmark localisation method for which all the bounding\n",
    "# boxes will be fit. Ensure that the respective model exists.\n",
    "method_landm_loc = 'aam'\n",
    "\n",
    "\n",
    "# Below are all the methods for which the landmarks will be fit. \n",
    "# They are separated into detection and tracking methods due \n",
    "# to the different models required, as well as for the different\n",
    "# pattern of their bb paths.\n",
    "detections_methods = ['dlib', 'opencv', 'ffld2', 'ramanan']\n",
    "tracking_methods = ['corr', 'fct', 'rpt', 'lrst', 'spot', 'tld', 'srdcf', \n",
    "                   'kcf', 'cmt', 'mil', 'struck', 'ivt', 'df',\n",
    "                   'staple', 'lct', 'meem', 'sir_pf', 'camshift']\n",
    "tracking_methods = ['superpixel']\n",
    "detections_methods = []\n",
    "# auxiliary lambda function used in the following lines\n",
    "nn = lambda n, i: n + i + '_' + method_landm_loc\n",
    "# detectors' pool\n",
    "fold_out_pool_0 = [nn('detection_', i) for i in detections_methods]\n",
    "f0 = ['detector_' + i for i in detections_methods]\n",
    "# trackers' pool\n",
    "fold_out_pool_1 = [nn('tracking_', i) for i in tracking_methods]\n",
    "f1 = ['tracker_' + i  for i in tracking_methods]\n",
    "# combine the two lists\n",
    "f_o_pool = fold_out_pool_0 + fold_out_pool_1\n",
    "f_d_o_pool = f0 + f1\n",
    "names = detections_methods + tracking_methods\n",
    "assert(len(f_d_o_pool) == len(f_o_pool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = listdir(path_base)\n",
    "\n",
    "for f0 in range(len(f_o_pool)):\n",
    "    # iterate over all the tracking/detection methods.\n",
    "    fold_out = f_o_pool[f0]\n",
    "    fold_det_out = f_d_o_pool[f0]\n",
    "    print('method: {}, detector: {}'.format(fold_out, fold_det_out))\n",
    "\n",
    "    # auxiliary for selecting the ll model.\n",
    "    if fold_det_out[:7] == 'tracker':\n",
    "        model_bb = 'gt_bb'\n",
    "    elif fold_det_out[:8] == 'detector':\n",
    "        model_bb = names[f0]\n",
    "    else:\n",
    "        raise ValueError('Not a valid option')\n",
    "    \n",
    "    # load prediction model\n",
    "    if method_landm_loc == 'dlibERT':\n",
    "        str1 = '{}modelln_{}_{}.model'.format(path_pickles, model_bb, method_landm_loc)\n",
    "        path_shape_pred = str1\n",
    "        model = shape_predictor(path_shape_pred)\n",
    "    else:\n",
    "        str1 = '{}modelln_{}_{}.pkl'.format(path_pickles, model_bb, method_landm_loc)\n",
    "        path_pkl = str1\n",
    "        model = mio.import_pickle(path_pkl)\n",
    "        \n",
    "    if ('aam' in fold_out) and ('detection' in fold_out):  # hack for detector's AAM.\n",
    "        p_regr = join(path_pickles, 'regressor_' + fold_det_out + '.pkl')\n",
    "        assert(isfile(p_regr))\n",
    "        reg_f = mio.import_pickle(p_regr)\n",
    "        regr1 = reg_f['regr']\n",
    "        \n",
    "    if 'aam' in fold_out:\n",
    "        # for compatibility with >=menpo.v0.7.2 and the respective menpofit\n",
    "        model._reference_shape = model.aam.reference_shape\n",
    "        model._scales = model.aam.scales\n",
    "        model._holistic_features = model.aam.holistic_features\n",
    "    elif 'sdm' in fold_out:\n",
    "        try:\n",
    "            # grigoris, 6/2016: This is a hack for ensuring compatibility with the \n",
    "            # latest menpofit. That is converting the earlier trained model to the\n",
    "            # latest release. This should not be required in case you train a new\n",
    "            # model with the current menpofit (and use it in the same version).\n",
    "            model._reference_shape = model.__dict__['reference_shape']\n",
    "            model._scales = model.__dict__['scales']\n",
    "            model._holistic_features = model.__dict__['holistic_features']\n",
    "        except KeyError:\n",
    "            # That's fine, maybe the model was trained with the latest menpofit.\n",
    "            pass\n",
    "        \n",
    "    # for each category in the testset, run landmark loc method\n",
    "    for cat in cats:\n",
    "        if not cat[:8] == 'category' or not isdir(path_base + cat):\n",
    "            warn('Unknown content in path {} (folder: {}).'.format(path_base, cat))\n",
    "        print(cat)\n",
    "        # join or create the paths\n",
    "        p_cat = join(path_base, cat, '')\n",
    "        # path of the frames:\n",
    "        p_fr = join(p_cat, 'frames', '')\n",
    "        # path where the ll files will be exported to.\n",
    "        p_ln_out_0 = mkdir_p(join(p_cat, fold_out, ''))\n",
    "        # path where the bb's of each frame (per clip) are located.\n",
    "        p_bb_out_0 = mkdir_p(join(p_cat, fold_det_out, ''))\n",
    "        # a dummy path for the workerbee files.\n",
    "        p_condor_dummy_0 = mkdir_p(join(p_cat, 'condor_tmp', \n",
    "                                        'condor_dummy_' + fold_out, ''))\n",
    "        assert(isdir(p_fr))\n",
    "\n",
    "        for c in sorted(listdir(p_fr)):   # for each clip\n",
    "            output_dir = Path(mkdir_p(p_condor_dummy_0 + c + sep))\n",
    "            done = lambda: output_dir.glob('*.pts')\n",
    "            im_paths = lambda: mio.image_paths(p_fr + c + sep + '*')\n",
    "            exhaust_all_files_randomly(im_paths, done, process_frame, verbose=True)\n",
    "        # uncomment below, only if NOT called in condor.\n",
    "    #     rm_if_exists(p_condor_dummy_0)\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print()\n",
    "execution_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
