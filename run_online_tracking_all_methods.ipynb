{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Performing landmark localisation when detector's/tracker's bounding box are already exported.\n",
    "Added also support for detectors (e.g. ramanan) when bb's exist. \n",
    "\n",
    "Difference from run_online_tracking: It runs for all methods (detectors + trackers) for \n",
    "a particular landmark localisation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from os.path import isdir, join, isfile, sep\n",
    "from os import listdir \n",
    "from functools import partial\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "from research_pyutils.path_related_functions import mkdir_p, rm_if_exists\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from workerbee import exhaust_all_files_randomly\n",
    "\n",
    "# menpo packages imports\n",
    "import menpo.io as mio\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "from menpodetect.ffld2 import load_ffld2_frontal_face_detector\n",
    "from menpodetect.dlib.conversion import pointgraph_to_rect\n",
    "from dlib import shape_predictor\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.landmark import LandmarkGroup\n",
    "from menpo.transform import Scale, Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the name of the computer, useful if running on condor\n",
    "import socket\n",
    "import time \n",
    "print(socket.gethostname())\n",
    "print(time.strftime(\"%d/%m/%Y, %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_base = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/300vw_testset/'\n",
    "assert(isdir(path_base))\n",
    "\n",
    "path_pickles = '/vol/atlas/homes/grigoris/misc/2016_ijcv/data/pickles/'\n",
    "assert(isdir(path_pickles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detection_to_pointgraph(detection):\n",
    "    return PointCloud(np.array([(p.y, p.x) for p in detection.parts()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _get_path(p0, name):\n",
    "    assert(isdir(p0))\n",
    "    p1 = join(p0, name, '')\n",
    "    if not isdir(p1):\n",
    "        mkdir_p(p1)\n",
    "    return p1\n",
    "\n",
    "\n",
    "def return_scale(pt, target_sz):\n",
    "    # find the current range of the bb (pt) and the scaling required to reach the target_sz.\n",
    "    # Used for the regression in detector's AAM only. \n",
    "    target_sz = np.array(target_sz) * 1.0\n",
    "    range0 = np.max(pt, axis=0) - np.min(pt, axis=0)\n",
    "    assert(np.min(range0) > 0)\n",
    "    scale = target_sz / range0\n",
    "    return scale\n",
    "\n",
    "\n",
    "def aam_regression(im, g):\n",
    "    # using global regr1, reg_f.\n",
    "    # The function resizes the bb based on the regression training, that is to \n",
    "    # scale/translate the detectors' bb towards the gt bb. \n",
    "    # It initially resizes the image, extracts the feats, acquires \n",
    "    # the prediction and then applies it on the detectors' bb.\n",
    "    \n",
    "    # Resizes the images based on the target_sz, extracts the feats in the resized bb, \n",
    "    # fit the regression, gets the prediction and applies the transform to the image.\n",
    "    # to the one the regression is trained on, extract feats\n",
    "    target_sz = reg_f['target_size']\n",
    "    feats = reg_f['feats']\n",
    "    \n",
    "    sc1 = return_scale(im.landmarks[g].lms.points, target_sz)\n",
    "    im2 = im.resize(sc1 * im.shape)\n",
    "\n",
    "    pt = im2.landmarks[g].lms.points\n",
    "    min_idx = np.round(np.min(pt, axis=0))\n",
    "    # often the size of the bb is 1 pixel off, so we specifically crop \n",
    "    #it to be in the target_sz.\n",
    "    im3 = feats(im2.crop(min_idx, min_idx + target_sz))\n",
    "    ft = np.reshape(im3.pixels, -1)\n",
    "    # predict from regression method\n",
    "    ft = ft.reshape(1, -1)  # avoid annoying warning of sklearn\n",
    "    pred = regr1.predict(ft)\n",
    "    \n",
    "#     im_n = im2.resize(pred[0, 0 : 2]  * im2.shape)\n",
    "#     pt = im_n.landmarks[g].lms.points\n",
    "#     # translate the bb landmark group\n",
    "#     im_n.landmarks['pred'] = PointCloud(pt + pred[0, 2 : 4])\n",
    "    \n",
    "    # get the reshaped bb, based on the prediction of the regressor.\n",
    "    # WARNING: The scaling as defined in the training is a pure scaling of the \n",
    "    # width, height, while with the transform in menpo, the bounding box moves\n",
    "    # towards [0,0], so we account for this change and add it to the translation.\n",
    "    scale = Scale(pred[0, 0 : 2])\n",
    "    centre = im.landmarks[g].lms.centre()\n",
    "    pcloud = scale.apply(im.landmarks[g].lms)\n",
    "    im.landmarks['pred'] = pcloud\n",
    "    diff_centre = centre - im.landmarks['pred'].lms.centre()\n",
    "    \n",
    "    transl = Translation(pred[0, 2 : 4] + diff_centre)\n",
    "    pcloud = transl.apply(im.landmarks['pred'].lms)\n",
    "    # the new bb is saved as pred landmark in the original image\n",
    "    im.landmarks['pred'] = pcloud\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "# def regression_transform_back(im, pred, shape):\n",
    "#     # reverse the changes made in the image\n",
    "#     pt = im.landmarks['final'].lms.points\n",
    "#     pt = pt - pred[0, 2 : 4]\n",
    "#     im.landmarks['final'] = PointCloud(pt + pred[0, 2 : 4])\n",
    "#     im2 = im.resize(shape)\n",
    "#     return im2.landmarks['final']\n",
    "\n",
    "def _area_bb(bb):\n",
    "    # accepts a list with a box in the format [y0, x0, y1, x1] and returns its area\n",
    "    return (bb[3] - bb[1] + 1) * (bb[2] - bb[0] + 1)\n",
    "    \n",
    "def compute_overlap(pt0, pt1):\n",
    "    # compute the overal of two bounding boxes (voc pascal as area of intersection / area of union)\n",
    "    # bbox in the form of [y0, x0, y1, x1]\n",
    "    # TODO: tests -> assert that outcome is 1 if called with same input, empty bb -> 0\n",
    "    b0 = [np.min(pt0[:, 0]), np.min(pt0[:, 1]), np.max(pt0[:, 0]), np.max(pt0[:, 1])]\n",
    "    b1 = [np.min(pt1[:, 0]), np.min(pt1[:, 1]), np.max(pt1[:, 0]), np.max(pt1[:, 1])]\n",
    "    # bounding box of intersection\n",
    "    bb_i = [max(b0[0], b1[0]), max(b0[1], b1[1]), \n",
    "                       min(b0[2], b1[2]), min(b0[3], b1[3])]\n",
    "    \n",
    "    inter_area = _area_bb(bb_i)\n",
    "    overlap = 0.\n",
    "    if (bb_i[3] - bb_i[1] + 1 > 0) and inter_area > 0:\n",
    "        union_area = _area_bb(b0) + _area_bb(b1) - inter_area\n",
    "        overlap = inter_area / union_area\n",
    "        \n",
    "    return overlap\n",
    "    \n",
    "    \n",
    "    \n",
    "def process_frame(p_fr):\n",
    "    # using global: p_ln_out_0, model, p_condor_dummy_0, p_bb_out_0, predictor_dlib(), min_sz\n",
    "    try:\n",
    "        im = mio.import_image(p_fr)\n",
    "        if im.n_channels == 3:\n",
    "            im = im.as_greyscale()\n",
    "        p_bb_out = _get_path(p_bb_out_0, im.path.parent.name) + im.path.stem\n",
    "        if isfile(p_bb_out + '.pts'):  # allow the _0.pts extension\n",
    "            p_bb_out += '.pts'\n",
    "        else:\n",
    "            p_bb_out += '_0.pts'\n",
    "\n",
    "        if isfile(p_bb_out):  # for this version, bb is loaded instead of detected\n",
    "            ln = mio.import_landmark_file(p_bb_out)\n",
    "            assert(ln.lms.n_points == 4)\n",
    "            \n",
    "            # catch the case of nan or overflowed values and don't try to fit those.\n",
    "            if ln.lms.has_nan_values() or np.any(ln.lms.points > 1e6):\n",
    "                print('The ln {} has nan or overflowed values.'.format(ln.path.stem))\n",
    "                # create dummy file for workerbee\n",
    "                p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "                open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "                return                \n",
    "\n",
    "            p_out = _get_path(p_ln_out_0, im.path.parent.name) + im.path.stem + '.pts'\n",
    "            # ensure that the bb is inside the bounds\n",
    "            im.landmarks['bb'] = ln\n",
    "            im.constrain_landmarks_to_bounds()\n",
    "            ln = im.landmarks['bb']\n",
    "            \n",
    "            if method_landm_loc == 'dlibERT':\n",
    "                im_pili = np.array(im.as_PILImage())\n",
    "                det_frame = predictor_dlib(im_pili, pointgraph_to_rect(ln.lms))\n",
    "                init_pc = detection_to_pointgraph(det_frame)\n",
    "                mio.export_landmark_file(LandmarkGroup.init_with_all_label(init_pc), \n",
    "                                         p_out, overwrite=True)\n",
    "            else:\n",
    "                if ('aam' in fold_out) and ('detection' in fold_out):   # hack to load regression model \n",
    "                    pred = aam_regression(im, 'bb')\n",
    "                    ov1 = compute_overlap(im.landmarks['pred'].lms.points, ln.lms.points)\n",
    "                    # detectors are not too off in their prediction, so require\n",
    "                    # some minimum overlap to replace with the regression's bb.\n",
    "                    if ov1 > 0.45 :\n",
    "                        im.constrain_landmarks_to_bounds()\n",
    "                        ln = im.landmarks['pred']\n",
    "                        \n",
    "                # catch the rare case of almost zero-size bb, in which case menpofit might crash.\n",
    "                bp = ln.lms.points\n",
    "                if np.all(np.max(bp, 0) - np.min(bp, 0) >= min_sz): \n",
    "                    ft = model.fit_from_bb(im, ln.lms)\n",
    "                    mio.export_landmark_file(ft.fitted_image.landmarks['final'], p_out, overwrite=True)\n",
    "                    print(' successfully fitted')  # helps in condor\n",
    "#                     shape = np.copy(im.shape)\n",
    "#                     im_n, pred, sc1 = aam_regression(im)\n",
    "#                     ln = im_n.landmarks['bb']\n",
    "#                     ft = model.fit_from_bb(im_n, ln.lms)\n",
    "#                     im1 = ft.fitted_image.copy()\n",
    "#                     ln = regression_transform_back(im1, pred, shape)\n",
    "#                     mio.export_landmark_file(ln, p_out, overwrite=True)\n",
    "#                 else:\n",
    "#                     ft = model.fit_from_bb(im, ln.lms)\n",
    "#                     mio.export_landmark_file(ft.fitted_image.landmarks['final'], p_out, overwrite=True)\n",
    "        else:  # temp, can be removed, debugging purposes. \n",
    "            print(\"The input '{}' has no ln.\".format(p_fr))\n",
    "        \n",
    "        # create dummy file for workerbee\n",
    "        p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "        open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "    except Exception as e:\n",
    "        print(\"The input '{}' failed with p_ln '{}'.\".format(p_fr, p_out))\n",
    "        logging.exception(\"The input '{}' failed.\".format(p_fr))\n",
    "        if ('aam' in fold_out) and ('detection' in fold_out):   # hack to load regression model \n",
    "            try:\n",
    "                print(e)\n",
    "                # create dummy file for workerbee\n",
    "                p_cond = _get_path(p_condor_dummy_0, im.path.parent.name)\n",
    "                open(p_cond + im.path.stem + '.pts', 'a').close() \n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_sz = np.array([10, 10])  # minimum size of bb we 'allow'.\n",
    "method_landm_loc = 'aam'\n",
    "\n",
    "detections_methods = ['dlib', 'opencv', 'ffld2', 'ramanan']\n",
    "tracking_methods = ['corr', 'fct', 'rpt', 'lrst', 'spot', 'tld', 'srdcf', \n",
    "                   'kcf', 'cmt', 'mil']\n",
    "# detectors' pool\n",
    "fold_out_pool_0 = ['detection_' + i + '_' + method_landm_loc for i in detections_methods]\n",
    "f0 = ['detector_' + i for i in detections_methods]\n",
    "# trackers' pool\n",
    "fold_out_pool_1 = ['tracking_' + i + '_' + method_landm_loc for i in tracking_methods]\n",
    "f1 = ['tracker_' + i  for i in tracking_methods]\n",
    "# combine the two lists\n",
    "f_o_pool = fold_out_pool_0 + fold_out_pool_1\n",
    "f_d_o_pool = f0 + f1\n",
    "names = detections_methods + tracking_methods\n",
    "assert(len(f_d_o_pool) == len(f_o_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = listdir(path_base)\n",
    "\n",
    "for f0 in range(len(f_o_pool)):\n",
    "    fold_out = f_o_pool[f0]\n",
    "    fold_det_out = f_d_o_pool[f0]\n",
    "    print('method: {}, detector: {}'.format(fold_out, fold_det_out))\n",
    "\n",
    "    if fold_det_out[:7] == 'tracker':\n",
    "        model_bb = 'gt_bb'\n",
    "    elif fold_det_out[:8] == 'detector':\n",
    "        model_bb = names[f0]\n",
    "    else:\n",
    "        raise ValueError('Not a valid option')\n",
    "    \n",
    "    # load prediction model\n",
    "    if method_landm_loc == 'dlibERT':\n",
    "        path_shape_pred = path_pickles + 'modelln_' +  model_bb + '_' + method_landm_loc + '.model'\n",
    "        assert(isfile(path_shape_pred))\n",
    "        predictor_dlib = shape_predictor(path_shape_pred)\n",
    "        model = 'dummy'  # just for deleting the models in the else below\n",
    "    else:\n",
    "        path_pkl = path_pickles + 'modelln_' +  model_bb + '_' + method_landm_loc + '.pkl'\n",
    "        assert(isfile(path_pkl))\n",
    "        model = mio.import_pickle(path_pkl)\n",
    "        \n",
    "    if ('aam' in fold_out) and ('detection' in fold_out):  # hack for detector's AAM.\n",
    "        p_regr = join(path_pickles, 'regressor_' + fold_det_out + '.pkl')\n",
    "        assert(isfile(p_regr))\n",
    "        reg_f = mio.import_pickle(p_regr)\n",
    "        regr1 = reg_f['regr']\n",
    "        \n",
    "    # for each category in the testset, run landmark loc method\n",
    "    for cat in cats:\n",
    "        if not cat[:8] == 'category' or not isdir(path_base + cat):\n",
    "            warn('Unknown content in path {} (folder: {}).'.format(path_base, cat))\n",
    "        print(cat)\n",
    "        # join or create the paths\n",
    "        p_cat = join(path_base, cat, '')\n",
    "        p_fr = join(p_cat, 'frames', '')\n",
    "        p_ln_out_0 = mkdir_p(join(p_cat, fold_out, ''))\n",
    "        p_bb_out_0 = mkdir_p(join(p_cat, fold_det_out, ''))\n",
    "        p_condor_dummy_0 = mkdir_p(join(p_cat, 'condor_tmp', 'condor_dummy_' + fold_out, ''))\n",
    "        assert(isdir(p_fr))  # frames folder should exist\n",
    "\n",
    "        for c in sorted(listdir(p_fr)):   # for each clip\n",
    "            output_dir = Path(mkdir_p(p_condor_dummy_0 + c + sep))\n",
    "            done = lambda: output_dir.glob('*.pts')\n",
    "            im_paths = lambda: mio.image_paths(p_fr + c + '/*')\n",
    "            exhaust_all_files_randomly(im_paths, done, process_frame, verbose=True)\n",
    "        # uncomment elow, only if NOT called in condor.\n",
    "    #     rm_if_exists(p_condor_dummy_0)\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "print()\n",
    "print(time.strftime(\"%d/%m/%Y, %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
